#Використовуючи модуль corpus прочитайте текст austin-persuasion.txt. Визначить скільки tokens (слів) і type (унікальних слів)містить ця книжка.
>>> import nltk
>>> nltk.corpus.gutenberg.fileids()
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']
>>> per = nltk.corpus.gutenberg.raw('austen-persuasion.txt')
>>> per
'[Persuasion by Jane Austen 1818]\n\n\nChapter 1\n\n\nSir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,\nfor his own amusement, never took up any book but the Baronetage;\nthere he found occupation for an idle hour, and consolation in a\ndistressed one; there his faculties were roused into admiration and\nrespect, by contemplating the limited remnant of the earliest patents;\nthere any unwelcome sensations, arising from domestic affairs\nchanged naturally into pity and contempt as he turned over\nthe almost endless creations of the last century; and there,\nif every other leaf were powerless, he could read his own history\nwith an interest which never failed.  This was the page at which\nthe favourite volume always opened:\n\n           "ELLIOT OF KELLYNCH HALL.\n\n"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth,\ndaughter of James Stevenson, Esq. of South Park, in the county of\nGloucester, by which lady (who died 1800) he has issue Elizabeth,\nborn June 1, 1785; Anne, born August 9, 1787; a still-born son,\nNovember 5, 1789; Mary, born November 20, 1791."\n\nPrecisely such had the paragraph originally stood from the printer\'s hands;\nbut Sir Walter had improved it by adding, for the information of\nhimself and his family, these words, after the date of Mary\'s birth--\n"Married, December 16, 1810, Charles, son and heir of Charles\nMusgrove, Esq. of Uppercross, in the county of Somerset,"\nand by inserting most accurately the day of the month on which\nhe had lost his wife.\n\nThen followed the history and rise of the ancient and respectable family,\nin the usual terms; how it had been first settled in Cheshire;\nhow mentioned in Dugdale, serving the office of high sheriff,\nrepresenting a borough in three successive parliaments,\nexertions of loyalty, and dignity of baronet, in the first year\nof Charles II, with all the Marys and Elizabeths they had married;\nforming altogether two handsome duodecimo pages, and concluding with\nthe arms and motto:--"Principal seat, Kellynch Hall, in the county\nof Somerset," and Sir Walter\'s handwriting again in this finale:--\n\n"Heir presumptive, William Walter Elliot, Esq., great grandson of\nthe second Sir Walter."\n\nVanity was the beginning and the end of Sir Walter Elliot\'s character;\nvanity of person and of situation.  He had been remarkably handsome\nin his youth; and, at fifty-four, was still a very fine man.\nFew women could think more of their personal appearance than he did,\nnor could the valet of any new made lord be more delighted with\nthe place he held in society.  He considered the blessing of beauty\nas inferior only to the blessing of a baronetcy; and the Sir Walter Elliot,\nwho united these gifts, was the constant object of his warmest respect\nand devotion.\n\nHis good looks and his rank had one fair claim on his attachment;\nsince to them he must have owed a wife of very superior character\nto any thing deserved by his own.  Lady Elliot had been an excellent woman,\nsensible and amiable; whose judgement and conduct, if they might be\npardoned the youthful infatuation which made her Lady Elliot,\nhad never required indulgence afterwards.--She had humoured,\nor softened, or concealed his failings, and promoted his real\nrespectability for seventeen years; and though not the very happiest\nbeing in the world herself, had found enough in her duties, her friends,\nand her children, to attach her to life, and make it no matter of\nindifference to her when she was called on to quit them.\n--Three girls, the two eldest sixteen and fourteen, was an awful legacy\nfor a mother to bequeath, an awful charge rather, to confide to\nthe authority and guidance of a conceited, silly father.\nShe had, however, one very intimate friend, a sensible, deserving woman,\nwho had been brought, by strong attachment to herself, to settle\nclose by her, in the village of Kellynch; and on her kindness and advice,\nLady Elliot mainly relied for the best help and maintenance of\nthe good principles and instruction which she had been anxiously\ngiving her daughters.\n\nThis friend, and Sir Walter, did not marry, whatever might have been\nanticipated on that head by their acquaintance.  Thirteen years\nhad passed away since Lady Elliot\'s death, and they were still\nnear neighbours and intimate friends, and one remained a widower,\nthe other a widow.\n\nThat Lady Russell, of steady age and character, and extremely\nwell provided for, should have no thought of a second marriage,\nneeds no apology to the public, which is rather apt to be unreasonably\ndiscontented when a woman does marry again, than when she does not;\nbut Sir Walter\'s continuing in singleness requires explanation.\nBe it known then, that Sir Walter...]

>>> import nltk

>>> nltk.corpus.gutenberg.fileids()
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']
>>> token = nltk.corpus.gutenberg.words('austen-persuasion.txt')
>>> token
['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...]
>>> len(token)
98171
>>> from __future__ import division
>>> len(set(token))/len(token)
0.062462437990852694
>>> import nltk
>>> from nltk.corpus import gutenberg
>>> from nltk import FreqDist
>>> text = gutenberg.words('austen-persuasion.txt')
>>> fdist = FreqDist([w.lower() for w in text])
>>> fdist1 = FreqDist(text)
>>> print(fdist)
<FreqDist: ',': 6750, 'the': 3329, 'to': 2808, 'and': 2801, '.': 2741, 'of': 2570, 'a': 1595, 'in': 1389, 'was': 1337, ';': 1290, ...>
#Виберіть пару текстів і дослідіть відмінності між ними (кількість оригінальних слів, багатство мови, жанр). Знайдіть слова, які мають різний зміст в цих текстах, подібно до слова monstrous в Moby Dick та у Sense and Sensibility. 
>>> import nltk

>>> nltk.corpus.gutenberg.fileids()
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']

>>> from __future__ import division
>>> import nltk
>>> from nltk.corpus import gutenberg
>>> from nltk import FreqDist
>>> text = gutenberg.words('chesterton-brown.txt')
>>> fdist = FreqDist([w.lower() for w in text])
>>> fdist1 = FreqDist(text)
>>> print(fdist)
<FreqDist: 'the': 4670, ',': 4069, '.': 2784, 'and': 2221, 'a': 2132, 'of': 2093, '"': 1461, 'to': 1391, 'he': 1357, 'in': 1253, ...>
>>> fdist=FreqDist(text)
>>> fdist
<FreqDist with 8299 samples and 86063 outcomes>
>>> vocab=fdist.keys()
>>> vocab[:200]
['the', ',', '.', 'of', 'a', 'and', '"', 'to', 'in', 'was', 'I', 'he', "'", 'his', 'that', 'it', ';', 'with', 'you', 'as', '-', 'had', ',"', 'but', 'on', 'is', '."', 's', 'at', 'said', 'for', 'him', 'The', 'like', 'not', 'He', 'be', 'man', 't', 'or', 'have', 'one', 'Brown', 'by', 'this', 'all', '?"', 'were', 'which', 'an', 'from', 'more', '--', 'out', 'But', 'Father', 'so', 'if', 'up', 'there', 'It', 'very', 'my', 'about', 'who', 'me', 'they', ':', 'could', 'other', 'some', 'than', 'are', 'know', 'been', 'And', 'little', 'rather', 'into', 'only', 'what', 'priest', 'would', 'think', 'when', 'Flambeau', 'no', 'can', 'down', 'old', 'her', 'did', 'do', 'them', 'two', 'face', 'will', 'looked', 'seemed', 'You', 'black', 'even', 'something', 'still', 'then', 'we', 'Mr', 'head', 'see', 'their', 'has', 'just', 'say', 'long', 'such', '?', 'she', 'quite', 'don', 'made', 'over', 'any', 'eyes', 'asked', 'before', 'heard', 'your', 'back', 'himself', '!"', 'house', 'mean', 'great', 'door', 'There', 'came', 'never', 'first', 'Then', 'here', 'room', 'cried', 'might', 'voice', 'way', 'most', 'must', 'looking', 'come', 'own', 'well', 'They', 'after', 'place', 'went', 'Well', 'much', 'really', 'sort', 'though', 'again', 'thing', 'things', 'look', 'tell', 'now', 'hair', 'men', 'saw', 'stood', 'because', 'yet', 'almost', 'figure', 'its', 'round', 'sea', 'thought', 'time', 'A', 'His', 'dark', 'found', '(', 'What', 'those', 'friend', 'should', 'where', 'white', 'got', 'hat', 'off', 'table', 'hand', 'red', '--"', 'Boulnois', 'away', 'garden']
>>> text1=gutenberg.words('milton-paradise.txt')
>>> fdist = FreqDist([w.lower() for w in text1])
>>> fdist1 = FreqDist(text1)
>>> fdist
<FreqDist with 9021 samples and 96825 outcomes>
>>> vocab[:200]
['the', ',', '.', 'of', 'a', 'and', '"', 'to', 'in', 'was', 'I', 'he', "'", 'his', 'that', 'it', ';', 'with', 'you', 'as', '-', 'had', ',"', 'but', 'on', 'is', '."', 's', 'at', 'said', 'for', 'him', 'The', 'like', 'not', 'He', 'be', 'man', 't', 'or', 'have', 'one', 'Brown', 'by', 'this', 'all', '?"', 'were', 'which', 'an', 'from', 'more', '--', 'out', 'But', 'Father', 'so', 'if', 'up', 'there', 'It', 'very', 'my', 'about', 'who', 'me', 'they', ':', 'could', 'other', 'some', 'than', 'are', 'know', 'been', 'And', 'little', 'rather', 'into', 'only', 'what', 'priest', 'would', 'think', 'when', 'Flambeau', 'no', 'can', 'down', 'old', 'her', 'did', 'do', 'them', 'two', 'face', 'will', 'looked', 'seemed', 'You', 'black', 'even', 'something', 'still', 'then', 'we', 'Mr', 'head', 'see', 'their', 'has', 'just', 'say', 'long', 'such', '?', 'she', 'quite', 'don', 'made', 'over', 'any', 'eyes', 'asked', 'before', 'heard', 'your', 'back', 'himself', '!"', 'house', 'mean', 'great', 'door', 'There', 'came', 'never', 'first', 'Then', 'here', 'room', 'cried', 'might', 'voice', 'way', 'most', 'must', 'looking', 'come', 'own', 'well', 'They', 'after', 'place', 'went', 'Well', 'much', 'really', 'sort', 'though', 'again', 'thing', 'things', 'look', 'tell', 'now', 'hair', 'men', 'saw', 'stood', 'because', 'yet', 'almost', 'figure', 'its', 'round', 'sea', 'thought', 'time', 'A', 'His', 'dark', 'found', '(', 'What', 'those', 'friend', 'should', 'where', 'white', 'got', 'hat', 'off', 'table', 'hand', 'red', '--"', 'Boulnois', 'away', 'garden']


>>> from nltk.corpus import brown
>>> brown.categories()
['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']
>>> cfd = nltk.ConditionalFreqDist(
	(genre, word)
	for genre in brown.categories()
	for word in brown.words(categories=genre))
>>> genres = ['religion', 'hobbies','romance']
>>> modals = ['believe', 'why', 'passion', 'love', 'must']
>>> cfd.tabulate(conditions=genres, samples=modals)
         believe  why passion love must
religion   12   14    1   13   54
 hobbies    4   10    0    6   83
 romance   14   34    5   32   45
>>> 
Python 2.7.3 (default, Apr 10 2012, 23:31:26) [MSC v.1500 32 bit (Intel)] on win32
Type "copyright", "credits" or "license()" for more information.
>>> import nltk
>>> nltk.corpus.gutenberg.fileids()
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']
>>> token = nltk.corpus.gutenberg.words('austen-persuasion.txt')token = nltk.corpus.gutenberg.words('austen-persuasion.txt')
SyntaxError: invalid syntax
>>> 
>>> token = nltk.corpus.gutenberg.words('austen-persuasion.txt')
>>> token
['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...]
>>> len(token)
98171
>>> sorted(set(token))
[...'superiority', 'superiors', 'supplanted', 'supplement', 'supplied', 'supplies', 'supply', 'support', 'supportable', 'supported', 'supporting', 'supports', 'suppose', 'supposed', 'supposes', 'supposing', 'supposition', 'suppositions', 'suppressed', 'sure', 'surely', 'surface', 'surgeon', 'surmised', 'surmounting', 'surname', 'surprise', 'surprised', 'surprises', 'surrounded', 'surrounding', 'surveyor', 'susceptible', 'suspect', 'suspected', 'suspecting', 'suspend', 'suspended', 'suspense', 'suspension', 'suspicion', 'suspicions', 'suspicious', 'sway', 'swear', 'swears', 'sweeps', 'sweet', 'sweeter', 'sweetness', 'sweets', 'swept', 'swinging', 'switch', 'syllable', 'sympathetic', 'sympathising', 'sympathize', 'sympathized', 'sympathy', 'symptom', 'symptoms', 't', 'table', 'tables', 'take', 'taken', 'takes', 'taking', 'tale', 'talents', 'talk', 'talked', 'talking', 'talks', 'tall', 'tapping', 'taste', 'tastes', 'tasting', 'taught', 'tauntingly', 'tawny', 'tax', 'taxes', 'tea', 'teach', 'tearing', 'tears', 'tease', 'teasing', 'teaze', 'teazing', 'teeth', 'tell', 'telling', 'tells', 'temper', 'temperament', 'tempered', 'tempers', 'temples', 'tempt', 'temptation', 'tempted', 'tempting', 'ten', 'tenacious', 'tenant', 'tenantry', 'tenants', 'tendency', 'tender', 'tenderest', 'tenderness', 'tenements', 'term', 'terms', 'terror', 'test', 'testify', 'testimonies', 'testimony', 'than', 'thank', 'thankful', 'thankfulness', 'thanks', 'that', 'the', 'theatre', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'theory', 'there', 'therefore', 'these', 'they', 'thick', 'thicker', 'thickest', 'thin', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'thirteen', 'thirty', 'this', 'thither', 'thorough', 'thoroughfare', 'thoroughly', 'those', 'though', 'thought', 'thoughtful', 'thoughtfulness', 'thoughtless', 'thoughtlessness', 'thoughts', 'thousand', 'thousands', 'thread', 'threatenings', 'three', 'threw', 'thrill', 'throat', 'throats', 'through', 'throughout', 'throw', 'throwing', 'thrown', 'thus', 'tide', 'tidings', 'tied', 'tight', 'till', 'time', 'times', 'timidity', 'tired', 'tiresome', 'title', 'to', 'today', 'together', 'toil', 'toiling', 'toils', 'toilsome', 'told', 'tolerable', 'tolerably', 'tolerate', 'tolerated', 'tone', 'tones', 'tongue', 'too', 'took', 'tooth', 'top', 'topic', 'topics', 'torment', 'torn', 'tossed', 'total', 'totally', 'touch', 'touched', 'toward', 'towards', 'town', 'toys', 'trace', 'tradespeople', 'trained', 'tranquillity', 'tranquillized', 'transformed', 'transgressed', 'transgressions', 'transient', 'translate', 'transmitted', 'transplanted', 'transposed', 'trash', 'travelled', 'traveller', 'travelling', 'trays', 'treachery', 'treading', 'treason'...]

>>> len(set(token))
6132

>>> from __future__ import division
>>> def lexical_diversity(token):
	return len (set(token)) / len(token)

>>> def percentage(count, total):
	return 100 * count / total

>>> lexical_diversity(token)
0.062462437990852694
>>> token1 = nltk.corpus.gutenberg.words('austen-sense.txt')
>>> token1
['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', ...]
>>> len(token1)
141576
>>> sorted(set(token))
[...'flattered', 'flattering', 'flattery', 'flight', 'fling', 'flirting', 'floor', 'flow', 'flower', 'flowing', 'flurried', 'flushed', 'fly', 'flying', 'folded', 'folding', 'folks', 'follies', 'follow', 'followed', 'following', 'folly', 'fond', 'food', 'fool', 'foolish', 'foot', 'footing', 'footpath', 'footsteps', 'for', 'forbad', 'forbearance', 'forbearing', 'forbid', 'force', 'forced', 'foreboding', 'forego', 'foreign', 'foremost', 'foresaw', 'foresee', 'foreseeing', 'foreseen', 'foresight', 'forest', 'foretold', 'forget', 'forgetful', 'forgetfulness', 'forgets', 'forgetting', 'forgive', 'forgiven', 'forgot', 'forgotten', 'fork', 'form', 'formal', 'formality', 'formed', 'former', 'formerly', 'formidable', 'forming', 'forms', 'fors', 'forte', 'forth', 'fortify', 'fortitude', 'fortnight', 'fortunate', 'fortunately', 'fortune', 'forty', 'forward', 'forwardness', 'fought', 'foul', 'found', 'four', 'fourteen', 'fourth', 'fragments', 'frames', 'frank', 'frankness', 'fraternal', 'fraught', 'freckles', 'free', 'freedom', 'freehold', 'freely', 'frequent', 'frequenting', 'frequently', 'fresh', 'fresher', 'freshness', 'friend', 'friendliness', 'friendly', 'friends', 'friendship', 'frigate', 'fright', 'frightened', 'frightful', 'frights', 'from', 'front', 'frost', 'frosts', 'frosty', 'fruit', 'fruitless', 'full', 'fully', 'fund', 'funds', 'furnish', 'furnished', 'furnishing', 'furniture', 'further', 'future', 'futurity', 'gad', 'gadding', 'gaiety', 'gain', 'gained', 'gainer', 'gaining', 'gale', 'gallant', 'gallantry', 'game', 'gapes', 'garden', 'gardens', 'gate', 'gates', 'gave', 'gay', 'gaze', 'general', 'generally', 'generation', 'generosity', 'generous', 'generously', 'genius', 'genteel', 'gentle', 'gentleman', 'gentlemanlike', 'gentlemen', 'gentleness', 'gently', 'get', 'gets', 'getting', 'giddy', 'gift', 'gifted', 'gifts', 'gig', 'girl', 'girls', 'give', 'given', 'gives', 'giving', 'glad', 'gladden', 'gladly', 'glance', 'glanced', 'glances', 'glare', 'glass', 'glasses', 'gleaning', 'glee', 'glimpse', 'glimpses', 'gloom', 'gloomy', 'gloried', 'glories', 'glorious', 'glossy', 'gloves', 'glow', 'glowed', 'glowing', 'glued', 'gnawing', 'go', 'god', 'goes', 'going', 'gold', 'gone', 'good', 'goodness', 'gossip', 'got', 'gout', 'gouty', 'governance', 'governed', 'governess', 'governing', 'gown', 'grace', 'graceful', 'gracefully', 'graciously', 'graciousness', 'gradual', 'gradually', 'grand', 'grandchildren', 'grandeur', 'grandfather', 'grandfathers', 'grandmamma', 'grandson', 'grant', 'granted', 'grass', 'grateful', 'gratefully', 'gratification', 'gratified', 'gratify', 'gratifying', 'gratitude', 'grave', 'gravel', 'gravely', 'grazier', 'great', 'greater', 'greatest', 'greatly', 'green', 'greenhouse', 'greeted', 'grew', 'grey', 'grief', 'grievance', 'grievances', 'grieved', 'grieving', 'groom', 'gross', 'grossly', 'ground', 'grounds', 'group', 'groups', 'grove', 'groves', 'grow', 'growing', 'grown', 'grows', 'growth', 'guard', 'guarded', 'guarding', 'guess', 'guessed', 'guests', 'guidance', 'guide', 'guided', 'guile', 'guilt', 'guilty', 'gun', 'gunsmith', 'habit', 'habits', 'had', 'haggard', 'hail', 'hair', 'haired', 'hairs', 'hale', 'half', 'hammer', 'hand', 'handed', 'hands', 'handsome', 'handsomely', 'handsomer', 'handsomest', 'handwriting', 'hang', 'hanging', 'happen', 'happened', 'happening', 'happens', 'happier', 'happiest', 'happily', 'happiness', 'happy', 'harasses', 'harassing', 'hard', 'harden', 'hardened', 'harder', 'hardly', 'hardness', 'hardship', 'harm', 'harmony', 'harp', 'has', 'haste', 'hastened', 'hastily', 'hasty', 'hat', 'hate', 'hates', 'hating', 'have', 'having', 'hazard', 'hazarded', 'hazel', 'he', 'head', 'headache', 'headed', 'heads', 'headship', 'headstrong', 'health', 'healthy', 'heaped', 'hear', 'heard', 'hearing', 'hears', 'heart', 'hearted', 'heartily', 'heartiness', 'heartless', 'hearts', 'hearty', 'heat', 'heats', 'heave', 'heaven', 'heavens', 'heaviest', 'heavily', 'heavy', 'hedge', 'hedges', 'heedless', 'heedlessness', 'heels', 'height', 'heightened', 'heir', 'heirs', 'held', 'help', 'helped', 'helpless', 'hemmed', 'hence', 'her', 'herald', 'here', 'hereabouts', 'hereafter', 'heroism', 'hers', 'herself', 'hesitate', 'hesitated', 'hesitatingly', 'hesitation', 'hey', 'heyday', 'hid', 'hide'...]
>>> from __future__ import division

>>> def lexical_diversity(token1):
	return len(set(token1))/len(token1)

>>> def percentage (count, total):
	return 100*count/total

>>> lexical_diversity(token1)
0.04826383002768831
>>> 
#Напишіть програму для знаходження всіх слів в корпусі Brown, які зустрічаються не менш ніж три рази
>>> import nltk
>>> from nltk.corpus import brown
>>> t = brown.words(categories='news')
>>> t1 = brown.words(categories='adventure')
>>> t2 = brown.words(categories='fiction')
>>> t3 = brown.words(categories='hobbies')
>>> t4= brown.words(categories='reviews')
>>> t5= brown.words(categories='religion')
>>> t6= brown.words(categories='romance')
>>> t7= brown.words(categories='belles_lettres')
>>> t8= brown.words(categories='editorial')
>>> t9= brown.words(categories='humor')
>>> t10 = brown.words(categories='government')
>>> t11 = brown.words(categories='mystery')
>>> t12 = brown.words(categories='learned')
>>> t13 = brown.words(categories='lore')
>>> t14 = brown.words(categories='science_fiction')
>>> tt=t+t1+t2+t3+t4+t5+t6+t7+t8+t9+t10+t11+t12+t13+t14
>>> import nltk
>>> from nltk.corpus import brown
>>> from nltk import FreqDist
>>> fdist = FreqDist([w.lower() for w in tt])
fdist1 = FreqDist(tt)
sorted([w for w in set(tt) if  fdist1[w] > 3])
>>> fdist1 = FreqDist(tt)

>>> sorted([w for w in set(tt) if  fdist1[w] > 3])
[... 'According', 'Accordingly', 'Achievement', 'Acropolis', 'Across', 'Act', 'Acting', 'Action', 'Active', 'Activities', 'Actually', 'Ada', "Ada's", 'Adam', 'Adams', 'Add', 'Additional', 'Adelia', 'Adenauer', 'Adios', 'Adjusted', 'Adlai', 'Administration', 'Administrative', 'Ado', 'Adolf', 'Adoniram', 'Adrian', 'Advisory', 'Advocate', 'Aegean', 'Aerospace', 'Aeschylus', 'Af', 'Af-stage', 'Affairs', 'Africa', 'African', 'Africans', 'Afro-Asian', 'After', 'Afterwards', 'Again', 'Against', 'Age', 'Agency', 'Ages', 'Agnese', 'Agreement', 'Agriculture', 'Ah', 'Aid', 'Aids', "Ain't", 'Air', 'Aircraft', 'Airport', 'Aj', 'Al', 'Ala.', 'Alabama', 'Alan', 'Alas', 'Alaska', 'Alastor', 'Albany', 'Albert', 'Alec', "Alec's", 'Alex', "Alex's", 'Alexander', 'Alexandria', 'Alfred', 'Algerian']
#Напишіть програму генерації таблиці відношень  кількість слів/кількість оригінальних слів для всіх жанрів корпуса Brown. Проаналізуйте отримані результати та поясніть їх.
>>> import nltk
>>> from nltk.corpus import brown
>>> brown.categories()
['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']

>>> for fileid in brown.fileids():
	num_words = len(brown.words(fileid))
	num_vocab = len(set([w.lower() for w in brown.words(fileid)]))
	print int(num_words/num_vocab), fileid

	
2 ca01
2 ca02
2 ca03
2 ca04
3 ca05
2 ca06
2 ca07
2 ca08
2 ca09

#Напишіть програму для знаходження 50 найчастотніших слів в тексті, за виключенням незначущих слів.
>>> import nltk

>>> from nltk.corpus import gutenberg
>>> gutenberg.fileids()
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']
>>> blake = gutenberg.words('blake-poems.txt')
>>> import nltk
>>> from nltk.corpus import gutenberg
>>> from nltk import FreqDist
>>> fdist = FreqDist([w.lower() for w in blake])
>>> fdist = FreqDist(blake)
>>> fdist
<FreqDist with 1820 samples and 8354 outcomes>
>>> 
KeyboardInterrupt
>>> vocab=fdist.keys()
>>> vocab[:50]
[',', 'the', '.', 'And', 'and', 'of', 'I', 'in', 'a', "'", ';', 'to', ':', 'my', '?', 'The', '!', 'with', '"', 'his', 'is', 's', 'thee', 'not', 'he', 'me', 'on', 'their', 'her', 'all', 'they', 'was', 'like', 'from', 'thou', 'thy', 'THE', 'it', 'little', 'In', 'be', 'night', 'But', 'away', 'Then', 'd', 'joy', 'our', 'He', 'are']

>>> word_1=fdist.hapaxes()
>>> len(word_1)
1009
>>> word_1
['!"--', '\',"', '(', ')', ',--', '1780', '1789', ':!"', ';"', 'ABSTRACT', 'AH', 'ANCIENT', 'ANGEL', 'ANOTHER', 'ANSWER', 'APPENDIX', 'Adona', 'Alas', 'Albion', 'Alehouse', 'Am', 'An', 'Answerd', 'Appeared', 'Arm', 'Art', 'Author', 'BARD', 'BLACK', 'BLOSSOM', 'Bard', 'Because', 'Become', 'Began', 'Beneath', 'Bird', 'Blasts', 'Blown', 'Bore', 'Bound', 'Bowed', 'Brain', 'Break', 'Burnt', 'CLOD', 'Calling', 'Calls', 'Chained', 'Chase', 'Children', 'Clod', 'Cock', 'Cold', 'Comfort', 'Cruel', 'Crying', 'DREAM', 'Dacre', 'Dame', 'Day', 'Dear', 'Deceit', 'Descend', 'Devil', 'Dick', 'Dolors', 'Doubt', 'Down', 'Driven', 'Drop', 'EARTH', 'ECHOING', 'Eagle', 'Emily', 'Eternal', 'Eyelids', 'FLY', 'Famished', 'Farewell', 'Fed', 'Feed', 'Fled', 'Flowed', 'Fly', 'Folly', 'Frame', 'Free', 'Frowning', 'Full', 'GARDEN', 'GREEN', 'Giving', 'Gone', 'Grave', 'Graze', 'Grey', 'Guarded', 'HUMAN', 'Had', 'Hearing', 'Hears', 'Heaven', 'Heavenly', 'Helpless', 'Here', 'Him', 'Himself', 'Hoarse', 'Hovering', 'Humility', 'Hush', 'II', 'III', 'IV', 'Image', 'Into', 'JOY', 'Jack', 'Jealousy', 'Jesus', 'Jew', 'Joe', 'John', 'Joys', 'Know', 'LAMB', 'LAUGHING', 'LILY', 'LONDON', 'LOVE', 'Lark', 'Led', 'Leopards', 'Lilly', 'Lives', 'Lo', 'London', 'Look', 'Loosed', 'Lost', 'Lurch', 'Luvah', 'MY', 'Making', 'Many', 'Marks', 'Mary', 'May', 'Met', 'Mne', 'Mole', 'Motto', 'Must', 'NIGHT', 'NOTE', 'Naked', 'Ned', 'New', 'Nightingale', 'Nostril', 'Nothing', 'Nought', 'ON', 'Old', 'Ona', 'One', 'PEBBLE', 'POISON', 'PRETTY', 'Pale', 'Parents', 'Parson', 'Paul', 'Pipe', 'Pitying', 'Poems', 'Pouring', 'Prays', 'Priest', 'Printer', 'Prisoned', 'Reading', 'Receive', 'Return', 'Revives', 'Rises', 'Rising', 'Rose', 'Ruby', 'Ruddy', 'Runs', 'SCHOOLBOY', 'SHEPHERD', 'SICK', 'SPRING', 'SUNFLOWER', 'Say', 'Seated', 'Secresy', 'Seek', 'Sees', 'Self', 'Seraphim', 'Sit', 'Sits', 'Sitting', 'Sleeping', 'Smelling', 'Smiles', 'Softest', 'Sought', 'Sound', 'Sow', 'Speak', 'Spring', 'Starry', 'Starved', 'Stony', 'Strangers', 'Striving', 'Struggling', 'Susan', 'TERZAH', 'TIGER', 'TO', 'Tangled', 'Terror', 'Thousands', 'Thursday', 'Thus', 'Tongue', 'Trodden', 'Troubled', 'Truth', 'Turk', 'Turn', 'Turning', 'Twas', 'VAGABOND', 'VOICE', 'Viewed', 'Virgin', 'Walks', 'Warbled', 'Waves', 'Weave', 'Well', 'Wept', 'Were', 'Whate', 'Which', 'White', 'Whose', 'Willm', 'Wilt', 'Wisdom', 'Witless', 'Word', 'Worms', 'Worn', 'Wrath', 'Yet', 'You', '[', ']', 'about', 'abroad', 'ache', 'admired', 'afar', 'affright', 'against', 'aged', 'agree', 'ah', 'airy', 'ale', 'allay', 'alone', 'altar', 'always', 'ambush', 'annoy', 'answer', 'anvil', 'anxious', 'appall', 'appals', 'apparel', 'appears', 'apple', 'arm', 'arms', 'arose', 'arrow', 'arrows', 'artful', 'astonish', 'awoke', 'baits', 'balmy', 'ban', 'band', 'bandy', 'bane', 'bank', 'bar', 'barrel', 'beadles', 'bearing', 'bears', 'beast', 'beat', 'begone', 'beguiles', 'beheld', 'behind', 'behold'...]
#Напишіть функцію word_freq(), яка приймає слово і назву частини корпуса Brown як аргументи і визначає частоту слова в заданій частині корпуса.
import nltk
from nltk.corpus import brown
def word_freq(word, section):
	freq = nltk.probability.FreqDist(nltk.corpus.brown.words(categories = section))
	word_frequency = freq[word]
	return word_frequency
>>> word_freq('name','news')
15
>>> word_freq('interview', 'news')
6
>>> 

